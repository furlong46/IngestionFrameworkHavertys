{
	"name": "ETL_pl_AzureControlled_Subpipeline",
	"properties": {
		"activities": [
			{
				"name": "LookUp_JobConfigurationAzureMetadataList",
				"description": "This LookUp calls a stored procedure and returns the metadata for the DB2 tables that need to be copied to Azure Data Lake",
				"type": "Lookup",
				"dependsOn": [],
				"policy": {
					"timeout": "7.00:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"source": {
						"type": "AzureSqlSource",
						"sqlReaderStoredProcedureName": "[dbo].[usp_JobConfigurationAzureMetadataList]",
						"storedProcedureParameters": {
							"MasterProcessNumber": {
								"type": "Int32",
								"value": {
									"value": "@pipeline().parameters.MasterProcessNumber",
									"type": "Expression"
								}
							}
						}
					},
					"dataset": {
						"referenceName": "ds_AzureSqlTable_ETL_AzureMetadataIngestionList",
						"type": "DatasetReference"
					},
					"firstRowOnly": false
				}
			},
			{
				"name": "ForEach_CopyStagingRaw",
				"description": "This ForEach loops through the metadata list and copies data nto Staging and Raw in Azure Data Lake.",
				"type": "ForEach",
				"dependsOn": [
					{
						"activity": "LookUp_JobConfigurationAzureMetadataList",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"userProperties": [],
				"typeProperties": {
					"items": {
						"value": "@activity('LookUp_JobConfigurationAzureMetadataList').output.value",
						"type": "Expression"
					},
					"isSequential": false,
					"batchCount": 15,
					"activities": [
						{
							"name": "Copy_ADLStaging_ADLRaw",
							"description": "This activity copies data from the ADL Staging location into a Raw storage folder. File path and name are dynamically derived from the Metadata lookup.",
							"type": "Copy",
							"dependsOn": [
								{
									"activity": "Delete_ExistingRaw",
									"dependencyConditions": [
										"Completed"
									]
								},
								{
									"activity": "Switch_ServerName",
									"dependencyConditions": [
										"Succeeded"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"source": {
									"type": "ParquetSource",
									"storeSettings": {
										"type": "AzureBlobFSReadSettings",
										"recursive": true,
										"wildcardFileName": "*",
										"enablePartitionDiscovery": false
									}
								},
								"sink": {
									"type": "ParquetSink",
									"storeSettings": {
										"type": "AzureBlobFSWriteSettings"
									}
								},
								"enableStaging": false,
								"parallelCopies": {
									"value": "@pipeline().parameters.JobParallelism",
									"type": "Expression"
								}
							},
							"inputs": [
								{
									"referenceName": "ds_ADLSG2parquet_DataLakeIngestionDir",
									"type": "DatasetReference",
									"parameters": {
										"FolderPath": {
											"value": "@concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') )",
											"type": "Expression"
										}
									}
								}
							],
							"outputs": [
								{
									"referenceName": "ds_ADLSG2parquet_DataLakeIngestionDir",
									"type": "DatasetReference",
									"parameters": {
										"FolderPath": {
											"value": "@concat(replace(concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') ), 'staging', 'raw'), '/TS=',string(item().StartTime))",
											"type": "Expression"
										}
									}
								}
							]
						},
						{
							"name": "LookUp_JobTableLogStart",
							"description": "This LookUp calls a stored procedure which updates the status in the JobTableLog for each table being copied and returns JobTableLogID.",
							"type": "Lookup",
							"dependsOn": [],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"source": {
									"type": "AzureSqlSource",
									"sqlReaderStoredProcedureName": "[dbo].[usp_JobTableLogStart]",
									"storedProcedureParameters": {
										"JobConfiguration": {
											"type": "String",
											"value": {
												"value": "@pipeline().parameters.JobConfiguration",
												"type": "Expression"
											}
										},
										"MasterProcessNumber": {
											"type": "Int32",
											"value": {
												"value": "@pipeline().parameters.MasterProcessNumber",
												"type": "Expression"
											}
										},
										"SchemaTable": {
											"type": "String",
											"value": {
												"value": "@item().SchemaTable",
												"type": "Expression"
											}
										},
										"TableControlType": {
											"type": "String",
											"value": "Azure"
										},
										"TableID": {
											"type": "Int32",
											"value": {
												"value": "@item().TableID",
												"type": "Expression"
											}
										}
									}
								},
								"dataset": {
									"referenceName": "ds_AzureSqlTable_ETL_Master",
									"type": "DatasetReference"
								},
								"firstRowOnly": false
							}
						},
						{
							"name": "SP_JobTableLogEnd_Success",
							"description": "This stored procedure updates the JobTableLog status after successful execution of previous steps. ",
							"type": "SqlServerStoredProcedure",
							"dependsOn": [
								{
									"activity": "SP_AzureMetadataListUpdate",
									"dependencyConditions": [
										"Succeeded"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"storedProcedureName": "[dbo].[usp_JobTableLogEnd_Success]",
								"storedProcedureParameters": {
									"JobTableLogID": {
										"value": {
											"value": "@{activity('LookUp_JobTableLogStart').output.value[0].JobTableLogID}",
											"type": "Expression"
										},
										"type": "Int32"
									}
								}
							},
							"linkedServiceName": {
								"referenceName": "ls_AzureSqlDatabase_HavertysDW",
								"type": "LinkedServiceReference"
							}
						},
						{
							"name": "SP_JobTableLogEnd_Failure4",
							"description": "This stored procedures updates the status of the JobTableLog failed execution of previous steps.",
							"type": "SqlServerStoredProcedure",
							"dependsOn": [
								{
									"activity": "SP_AzureMetadataListUpdate",
									"dependencyConditions": [
										"Failed"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"storedProcedureName": "[dbo].[usp_JobTableLogEnd_Failure]",
								"storedProcedureParameters": {
									"JobTableLogID": {
										"value": {
											"value": "@{activity('LookUp_JobTableLogStart').output.value[0].JobTableLogID}",
											"type": "Expression"
										},
										"type": "Int32"
									}
								}
							},
							"linkedServiceName": {
								"referenceName": "ls_AzureSqlDatabase_HavertysDW",
								"type": "LinkedServiceReference"
							}
						},
						{
							"name": "SP_AzureMetadataListUpdate",
							"description": "This stored procedure updates the AzureMetadataIngestionList table with the start time of the most recent copy activity. This start time serves as the FilterColumnValue for DB2 queries in subsequent loads.  ",
							"type": "SqlServerStoredProcedure",
							"dependsOn": [
								{
									"activity": "Copy_ADLStaging_ADLRaw",
									"dependencyConditions": [
										"Succeeded"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"storedProcedureName": "[dbo].[usp_AzureMetadataListUpdate]",
								"storedProcedureParameters": {
									"JobTableLogID": {
										"value": {
											"value": "@{activity('LookUp_JobTableLogStart').output.value[0].JobTableLogID}",
											"type": "Expression"
										},
										"type": "Int32"
									}
								}
							},
							"linkedServiceName": {
								"referenceName": "ls_AzureSqlDatabase_HavertysDW",
								"type": "LinkedServiceReference"
							}
						},
						{
							"name": "SP_JobTableLogEnd_Failure3",
							"description": "This stored procedures updates the status of the JobTableLog failed execution of previous steps.",
							"type": "SqlServerStoredProcedure",
							"dependsOn": [
								{
									"activity": "Copy_ADLStaging_ADLRaw",
									"dependencyConditions": [
										"Failed"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"storedProcedureName": "[dbo].[usp_JobTableLogEnd_Failure]",
								"storedProcedureParameters": {
									"JobTableLogID": {
										"value": {
											"value": "@{activity('LookUp_JobTableLogStart').output.value[0].JobTableLogID}",
											"type": "Expression"
										},
										"type": "Int32"
									}
								}
							},
							"linkedServiceName": {
								"referenceName": "ls_AzureSqlDatabase_HavertysDW",
								"type": "LinkedServiceReference"
							}
						},
						{
							"name": "SP_JobTableLogEnd_Failure2",
							"description": "This stored procedures updates the status of the JobTableLog failed execution of previous steps.",
							"type": "SqlServerStoredProcedure",
							"dependsOn": [
								{
									"activity": "Switch_ServerName",
									"dependencyConditions": [
										"Failed"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"storedProcedureName": "[dbo].[usp_JobTableLogEnd_Failure]",
								"storedProcedureParameters": {
									"JobTableLogID": {
										"value": {
											"value": "@{activity('LookUp_JobTableLogStart').output.value[0].JobTableLogID}",
											"type": "Expression"
										},
										"type": "Int32"
									}
								}
							},
							"linkedServiceName": {
								"referenceName": "ls_AzureSqlDatabase_HavertysDW",
								"type": "LinkedServiceReference"
							}
						},
						{
							"name": "Delete_ExistingStaging",
							"description": "This activity deletes all existing files in the destination staging folder for each file being copied.",
							"type": "Delete",
							"dependsOn": [
								{
									"activity": "LookUp_JobTableLogStart",
									"dependencyConditions": [
										"Succeeded"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"dataset": {
									"referenceName": "ds_ADLSG2parquet_DataLakeIngestionDir",
									"type": "DatasetReference",
									"parameters": {
										"FolderPath": {
											"value": "@concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') )",
											"type": "Expression"
										}
									}
								},
								"enableLogging": false,
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true
								}
							}
						},
						{
							"name": "Delete_ExistingRaw",
							"description": "This activity deletes files that have the same start time as the current run (i.e. only when this is a rerun). Therefore, most of the time this activity will not delete any files and will fail. The pipeline will continue upon completion of this activity - not success.",
							"type": "Delete",
							"dependsOn": [
								{
									"activity": "Delete_ExistingStaging",
									"dependencyConditions": [
										"Completed"
									]
								}
							],
							"policy": {
								"timeout": "7.00:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"dataset": {
									"referenceName": "ds_ADLSG2parquet_DataLakeIngestionDir",
									"type": "DatasetReference",
									"parameters": {
										"FolderPath": {
											"value": "@concat(replace(concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') ), 'staging', 'raw'), '/TS=',string(item().StartTime))",
											"type": "Expression"
										}
									}
								},
								"enableLogging": false,
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true
								}
							}
						},
						{
							"name": "Execute ETL_pl_Error_StoredProcedure_Execute_2",
							"type": "ExecutePipeline",
							"dependsOn": [
								{
									"activity": "SP_JobTableLogEnd_Failure2",
									"dependencyConditions": [
										"Succeeded"
									]
								}
							],
							"userProperties": [],
							"typeProperties": {
								"pipeline": {
									"referenceName": "ETL_pl_Error_StoredProcedure_Execute",
									"type": "PipelineReference"
								},
								"waitOnCompletion": true,
								"parameters": {
									"MasterProcessNumber": {
										"value": "@pipeline().parameters.MasterProcessNumber",
										"type": "Expression"
									},
									"RunType": {
										"value": "@pipeline().parameters.RunType",
										"type": "Expression"
									},
									"RunId": {
										"value": "@pipeline().RunId",
										"type": "Expression"
									},
									"CallingPipelineName": {
										"value": "@pipeline().Pipeline",
										"type": "Expression"
									},
									"ErrorMessage": {
										"value": "@concat('Could not ingest ', item().SchemaTable)",
										"type": "Expression"
									}
								}
							}
						},
						{
							"name": "Execute ETL_pl_Error_StoredProcedure_Execute_3",
							"type": "ExecutePipeline",
							"dependsOn": [
								{
									"activity": "SP_JobTableLogEnd_Failure3",
									"dependencyConditions": [
										"Succeeded"
									]
								}
							],
							"userProperties": [],
							"typeProperties": {
								"pipeline": {
									"referenceName": "ETL_pl_Error_StoredProcedure_Execute",
									"type": "PipelineReference"
								},
								"waitOnCompletion": true,
								"parameters": {
									"MasterProcessNumber": {
										"value": "@pipeline().parameters.MasterProcessNumber",
										"type": "Expression"
									},
									"RunType": {
										"value": "@pipeline().parameters.RunType",
										"type": "Expression"
									},
									"ErrorMessage": {
										"value": "@activity('Copy_ADLStaging_ADLRaw').Error.Message",
										"type": "Expression"
									},
									"RunId": {
										"value": "@pipeline().RunId",
										"type": "Expression"
									},
									"CallingPipelineName": {
										"value": "@pipeline().Pipeline",
										"type": "Expression"
									}
								}
							}
						},
						{
							"name": "Execute ETL_pl_Error_StoredProcedure_Execute_4",
							"type": "ExecutePipeline",
							"dependsOn": [
								{
									"activity": "SP_JobTableLogEnd_Failure4",
									"dependencyConditions": [
										"Succeeded"
									]
								}
							],
							"userProperties": [],
							"typeProperties": {
								"pipeline": {
									"referenceName": "ETL_pl_Error_StoredProcedure_Execute",
									"type": "PipelineReference"
								},
								"waitOnCompletion": true,
								"parameters": {
									"MasterProcessNumber": {
										"value": "@pipeline().parameters.MasterProcessNumber",
										"type": "Expression"
									},
									"RunType": {
										"value": "@pipeline().parameters.RunType",
										"type": "Expression"
									},
									"ErrorMessage": {
										"value": "@activity('SP_AzureMetadataListUpdate').Error.Message",
										"type": "Expression"
									},
									"RunId": {
										"value": "@pipeline().RunId",
										"type": "Expression"
									},
									"CallingPipelineName": {
										"value": "@pipeline().Pipeline",
										"type": "Expression"
									}
								}
							}
						},
						{
							"name": "Switch_ServerName",
							"type": "Switch",
							"dependsOn": [
								{
									"activity": "Delete_ExistingStaging",
									"dependencyConditions": [
										"Completed"
									]
								}
							],
							"userProperties": [],
							"typeProperties": {
								"on": {
									"value": "@toUpper(item().ServerName)",
									"type": "Expression"
								},
								"cases": [
									{
										"value": "PC03002",
										"activities": [
											{
												"name": "Copy_DB2_ADLStaging_3002",
												"description": "A query returns applicable data for each from DB2 which is then copied into Azure Data Lake in a staging folder. File path and name are dynamically derived from the Metadata lookup.",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "Db2Source",
														"query": {
															"value": "@item().Query",
															"type": "Expression"
														},
														"sqlReaderQuery": {
															"value": "@item().SelectQuery",
															"type": "Expression"
														}
													},
													"sink": {
														"type": "ParquetSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														}
													},
													"enableStaging": false,
													"parallelCopies": {
														"value": "@pipeline().parameters.JobParallelism",
														"type": "Expression"
													},
													"dataIntegrationUnits": 32
												},
												"inputs": [
													{
														"referenceName": "ds_DB2_ingestion",
														"type": "DatasetReference"
													}
												],
												"outputs": [
													{
														"referenceName": "ds_ADLSG2parquet_DataLakeIngestionNamedFile",
														"type": "DatasetReference",
														"parameters": {
															"FolderPath": {
																"value": "@concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') )",
																"type": "Expression"
															},
															"FileName": {
																"value": "@concat(item().SchemaTable,'_',string(pipeline().parameters.MasterProcessNumber),'.parquet')",
																"type": "Expression"
															}
														}
													}
												]
											}
										]
									},
									{
										"value": "PC03004",
										"activities": [
											{
												"name": "Copy_DB2_ADLStaging_3004",
												"description": "A query returns applicable data for each from DB2 which is then copied into Azure Data Lake in a staging folder. File path and name are dynamically derived from the Metadata lookup.",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "Db2Source",
														"query": {
															"value": "@item().Query",
															"type": "Expression"
														},
														"sqlReaderQuery": {
															"value": "@item().SelectQuery",
															"type": "Expression"
														}
													},
													"sink": {
														"type": "ParquetSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														}
													},
													"enableStaging": false,
													"parallelCopies": {
														"value": "@pipeline().parameters.JobParallelism",
														"type": "Expression"
													},
													"dataIntegrationUnits": 32
												},
												"inputs": [
													{
														"referenceName": "ds_DB2_ingestion_sales_server",
														"type": "DatasetReference"
													}
												],
												"outputs": [
													{
														"referenceName": "ds_ADLSG2parquet_DataLakeIngestionNamedFile",
														"type": "DatasetReference",
														"parameters": {
															"FolderPath": {
																"value": "@concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') )",
																"type": "Expression"
															},
															"FileName": {
																"value": "@concat(item().SchemaTable,'_',string(pipeline().parameters.MasterProcessNumber),'.parquet')",
																"type": "Expression"
															}
														}
													}
												]
											}
										]
									},
									{
										"value": "PC04010",
										"activities": [
											{
												"name": "Copy_DB2_ADLStaging_4010",
												"description": "A query returns applicable data for each from DB2 which is then copied into Azure Data Lake in a staging folder. File path and name are dynamically derived from the Metadata lookup.",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "Db2Source",
														"query": {
															"value": "@item().Query",
															"type": "Expression"
														},
														"sqlReaderQuery": {
															"value": "@item().SelectQuery",
															"type": "Expression"
														}
													},
													"sink": {
														"type": "ParquetSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														}
													},
													"enableStaging": false,
													"parallelCopies": {
														"value": "@pipeline().parameters.JobParallelism",
														"type": "Expression"
													},
													"dataIntegrationUnits": 32
												},
												"inputs": [
													{
														"referenceName": "ds_DB2_ingestion_distribution_server",
														"type": "DatasetReference"
													}
												],
												"outputs": [
													{
														"referenceName": "ds_ADLSG2parquet_DataLakeIngestionNamedFile",
														"type": "DatasetReference",
														"parameters": {
															"FolderPath": {
																"value": "@concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') )",
																"type": "Expression"
															},
															"FileName": {
																"value": "@concat(item().SchemaTable,'_',string(pipeline().parameters.MasterProcessNumber),'.parquet')",
																"type": "Expression"
															}
														}
													}
												]
											}
										]
									}
								],
								"defaultActivities": [
									{
										"name": "Copy_DB2_ADLStaging_Default",
										"description": "A query returns applicable data for each from DB2 which is then copied into Azure Data Lake in a staging folder. File path and name are dynamically derived from the Metadata lookup.",
										"type": "Copy",
										"dependsOn": [],
										"policy": {
											"timeout": "7.00:00:00",
											"retry": 0,
											"retryIntervalInSeconds": 30,
											"secureOutput": false,
											"secureInput": false
										},
										"userProperties": [],
										"typeProperties": {
											"source": {
												"type": "Db2Source",
												"query": {
													"value": "@item().Query",
													"type": "Expression"
												},
												"sqlReaderQuery": {
													"value": "@item().SelectQuery",
													"type": "Expression"
												}
											},
											"sink": {
												"type": "ParquetSink",
												"storeSettings": {
													"type": "AzureBlobFSWriteSettings"
												}
											},
											"enableStaging": false,
											"parallelCopies": {
												"value": "@pipeline().parameters.JobParallelism",
												"type": "Expression"
											},
											"dataIntegrationUnits": 32
										},
										"inputs": [
											{
												"referenceName": "ds_DB2_ingestion",
												"type": "DatasetReference"
											}
										],
										"outputs": [
											{
												"referenceName": "ds_ADLSG2parquet_DataLakeIngestionNamedFile",
												"type": "DatasetReference",
												"parameters": {
													"FolderPath": {
														"value": "@concat( item().DataLakeStagingFolder, '/', replace(replace(item().SchemaTable, '.', '_'), 'del', '') )",
														"type": "Expression"
													},
													"FileName": {
														"value": "@concat(item().SchemaTable,'_',string(pipeline().parameters.MasterProcessNumber),'.parquet')",
														"type": "Expression"
													}
												}
											}
										]
									}
								]
							}
						}
					]
				}
			},
			{
				"name": "SP_MasterJobEnd_Failure",
				"description": "This stored procedure receives the MasterProcessNumber as input and updates the status of the MasterJob table after failed execution of previous steps.",
				"type": "SqlServerStoredProcedure",
				"dependsOn": [
					{
						"activity": "ForEach_CopyStagingRaw",
						"dependencyConditions": [
							"Failed"
						]
					}
				],
				"policy": {
					"timeout": "7.00:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"storedProcedureName": "[dbo].[usp_MasterJobEnd_Failure]",
					"storedProcedureParameters": {
						"MasterProcessNumber": {
							"value": {
								"value": "@pipeline().parameters.MasterProcessNumber",
								"type": "Expression"
							},
							"type": "Int32"
						}
					}
				},
				"linkedServiceName": {
					"referenceName": "ls_AzureSqlDatabase_HavertysDW",
					"type": "LinkedServiceReference"
				}
			},
			{
				"name": "Execute ETL_pl_Error_StoredProcedure_Execute",
				"type": "ExecutePipeline",
				"dependsOn": [
					{
						"activity": "SP_MasterJobEnd_Failure",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "ETL_pl_Error_StoredProcedure_Execute",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true,
					"parameters": {
						"MasterProcessNumber": {
							"value": "@pipeline().parameters.MasterProcessNumber",
							"type": "Expression"
						},
						"RunType": {
							"value": "@pipeline().parameters.RunType",
							"type": "Expression"
						},
						"RunId": {
							"value": "@pipeline().RunId",
							"type": "Expression"
						},
						"CallingPipelineName": {
							"value": "@pipeline().Pipeline",
							"type": "Expression"
						}
					}
				}
			}
		],
		"parameters": {
			"JobConfiguration": {
				"type": "string",
				"defaultValue": "NightlyLoad"
			},
			"MasterProcessNumber": {
				"type": "int",
				"defaultValue": 1
			},
			"JobParallelism": {
				"type": "int",
				"defaultValue": 10
			},
			"RunType": {
				"type": "string",
				"defaultValue": "N"
			}
		},
		"folder": {
			"name": "MasterPipeline/Deprecated"
		},
		"annotations": []
	},
	"type": "Microsoft.DataFactory/factories/pipelines"
}